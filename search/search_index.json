{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"K-Means Clustering \u00b6 **Pengertian K-Means Clustering ** \u00b6 K-Means Clustering adalah metode unsupervised learning . Yang dimana, digunakan pada data yang tidak memiliki label. Tujuan dari metode unsupervised learning salah satunya adalah melakukan clustering. Yaitu mengelompokkan data-data dengan karakter mirip. Untuk melakukan clustering Anda perlu algoritma yang mendukung untuk pengimplementasian dari metode tersebut, salah satunya K-means. Tujuan dari k-means sendiri membagi suatu data dalam beberapa cluster (kelompok) sebanyak k, yang dimana jumlah k-nya ditentukan oleh Anda dan diwakili oleh Mean (Rata-rata) . Mean dari setiap cluster di asumsikan sebagai ringkasan yang baik dari setiap observasi dari cluster tersebut. Dan, pada K-Means Clustering memiliki dua jenis data clustering yang sering dipergunakan dalam proses pengelompokan data yaitu Hierarchical dan Non-Hierarchical . Dan K-Means merupakan salah satu metode data clustering non-hierarchical atau Partitional Clustering . Metode K-Means Clustering berusaha mengelompokkan data yang ada ke dalam beberapa kelompok, dimana data dalam satu kelompok mempunyai karakteristik yang sama satu sama lainnya dan mempunyai karakteristik yang berbeda dengan data yang ada di dalam kelompok yang lain. Dengan kata lain, metode K-Means Clustering bertujuan untuk meminimalisasikan objective function yang diset dalam proses clustering dengan cara meminimalkan variasi antar data yang ada di dalam suatu cluster dan memaksimalkan variasi dengan data yang ada di cluster lainnya . Karakteristik K-Mean \u00b6 K-means sangat cepat dalam proses clustering. K-means sangat sensitive pada pembangkitan centroid awal secara random. Memungkinkan suatu cluster tidak mempunyai anggota. Hasil clustering dengan K-means bersifat unik (selalu berubah-ubah, terkadang baik, terkadang jelek). Kelebihan dan Kekurangan K-Means \u00b6 - Kelebihan Menggunakan prinsip yang sederhana, dapat dijelaskan dalam non-statistik Sangat fleksibel, dapat dengan mudah di adaptasi. Sangat umum digunakan Waktu yang dibutuhkan untuk menjalankan nya relatif cepat - Kekurangan Karena menggunakan k buah acak, tidak di jamin untuk menemukan kumpulan cluster yang optimal. Tidak optimal digunakan untuk data yang jumlahnya terlalu banyak sampai bermiliyar. Dapat terjadinya curse of dimensionality, apabila jarak antara cluster yang satu dengan yang lain memiliki banyak dimesi. IMPLEMENTASI PROGAM K - MEANS CLUSTERING \u00b6 Di sini, untuk pengimplementasian program saya menggunakan data berupa diabetes datasets . Selain data, pengimplementasian membutuhkan software untuk melakukan, pengcodingan program dan di sini saya menggunakan software spyder yang terkoneksi di dalam software anaconda . Alasan saya memilih software spyder, karena pada software spyder yang berada di dalam anaconda, librarynya telah terinstall semua. Tidak seperti pycharm yang harus menginstall librarynya secara manual terlebih dahulu. - ANACONDA \u00b6 - SPYDER \u00b6 \"LANGKAH - LANGKAH CODING\" \u200b - Pertama \u200b Lakukan pengimportan library dari python seperti : \u200b - Numpy -> Untuk operasi vektor dan matriks \u200b - Pandas -> Untuk memuat sebuah file ke dalam tabel virtual seperti spreadsheet. \u200b - Matpolib -> Untuk menyajikan visualisasi data cluster \u200b - Sklearn -> Untuk mengimport library data science import numpy as np import matplotlib.pyplot as plt import pandas as pd from sklearn.cluster import KMeans \u200b - Kedua dataset = pd.read_csv('diabetes.csv') x = dataset.iloc[:, [1, 2, 3, 4]].values wcss = [] Penjelasan : \u200b Coding di atas berfungsing untuk memanggil datasests diabetes. Dan juga untuk memilih baris dan kolom berdasarkan nomer, sesuai urutan bingkai datanya. Dan coding baris terakhir berfungsi untuk memaksimalkan jarak cluster. \u200b - Ketiga for i in range(1, 11): kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0) kmeans.fit(x) wcss.append(kmeans.inertia_) #Plotting the results onto a line graph, allowing us to observe 'The elbow' plt.plot(range(1, 11), wcss) plt.title('The elbow method') plt.xlabel('Number of clusters') plt.ylabel('WCSS') #within cluster sum of squares plt.show() kmeans = KMeans(n_clusters = 3, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0) y_kmeans = kmeans.fit_predict(x) plt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], s = 100, c = 'red', label = 'tested_positive') plt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'tested_negative') #Plotting the centroids of the clusters plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:,1], s = 100, c = 'yellow', label = 'Centroids') plt.legend() Penjelasan : \u200b Coding di atas, berfungsi untuk mengeksekusi dataset yang telah di panggil ke dalam program. Yang nantinya data itu, di kelompokkan masing - masing oleh program sesuai dengan inputan class masing - masing, antara tested positive atau tested negative. Dan untuk membedakan pengelompokkan antara class tested positive dan tested negative, mereka di berikan warna berbeda. Yaitu warna merah untuk tested positive sedangkan warna biru untuk tested negative. Sedangkan warna kuning berfungsi, untuk menampilkan pengelompokkan centroids dari seluruh data. Dan di dalam codingan di atas juga terdapat, coding yang berfungsi menampilkan elbow method. Elbow method berfungsi, membantu menemukan jumlah cluster yang tepat dalam dataset. - Output Program -","title":"Metode Clustering"},{"location":"#k-means-clustering","text":"","title":"K-Means Clustering"},{"location":"#pengertian-k-means-clustering","text":"K-Means Clustering adalah metode unsupervised learning . Yang dimana, digunakan pada data yang tidak memiliki label. Tujuan dari metode unsupervised learning salah satunya adalah melakukan clustering. Yaitu mengelompokkan data-data dengan karakter mirip. Untuk melakukan clustering Anda perlu algoritma yang mendukung untuk pengimplementasian dari metode tersebut, salah satunya K-means. Tujuan dari k-means sendiri membagi suatu data dalam beberapa cluster (kelompok) sebanyak k, yang dimana jumlah k-nya ditentukan oleh Anda dan diwakili oleh Mean (Rata-rata) . Mean dari setiap cluster di asumsikan sebagai ringkasan yang baik dari setiap observasi dari cluster tersebut. Dan, pada K-Means Clustering memiliki dua jenis data clustering yang sering dipergunakan dalam proses pengelompokan data yaitu Hierarchical dan Non-Hierarchical . Dan K-Means merupakan salah satu metode data clustering non-hierarchical atau Partitional Clustering . Metode K-Means Clustering berusaha mengelompokkan data yang ada ke dalam beberapa kelompok, dimana data dalam satu kelompok mempunyai karakteristik yang sama satu sama lainnya dan mempunyai karakteristik yang berbeda dengan data yang ada di dalam kelompok yang lain. Dengan kata lain, metode K-Means Clustering bertujuan untuk meminimalisasikan objective function yang diset dalam proses clustering dengan cara meminimalkan variasi antar data yang ada di dalam suatu cluster dan memaksimalkan variasi dengan data yang ada di cluster lainnya .","title":"**Pengertian K-Means Clustering **"},{"location":"#karakteristik-k-mean","text":"K-means sangat cepat dalam proses clustering. K-means sangat sensitive pada pembangkitan centroid awal secara random. Memungkinkan suatu cluster tidak mempunyai anggota. Hasil clustering dengan K-means bersifat unik (selalu berubah-ubah, terkadang baik, terkadang jelek).","title":"Karakteristik K-Mean"},{"location":"#kelebihan-dan-kekurangan-k-means","text":"- Kelebihan Menggunakan prinsip yang sederhana, dapat dijelaskan dalam non-statistik Sangat fleksibel, dapat dengan mudah di adaptasi. Sangat umum digunakan Waktu yang dibutuhkan untuk menjalankan nya relatif cepat - Kekurangan Karena menggunakan k buah acak, tidak di jamin untuk menemukan kumpulan cluster yang optimal. Tidak optimal digunakan untuk data yang jumlahnya terlalu banyak sampai bermiliyar. Dapat terjadinya curse of dimensionality, apabila jarak antara cluster yang satu dengan yang lain memiliki banyak dimesi.","title":"Kelebihan dan Kekurangan K-Means"},{"location":"#implementasi-progam-k-means-clustering","text":"Di sini, untuk pengimplementasian program saya menggunakan data berupa diabetes datasets . Selain data, pengimplementasian membutuhkan software untuk melakukan, pengcodingan program dan di sini saya menggunakan software spyder yang terkoneksi di dalam software anaconda . Alasan saya memilih software spyder, karena pada software spyder yang berada di dalam anaconda, librarynya telah terinstall semua. Tidak seperti pycharm yang harus menginstall librarynya secara manual terlebih dahulu.","title":"IMPLEMENTASI PROGAM K - MEANS CLUSTERING"},{"location":"#-anaconda","text":"","title":"- ANACONDA"},{"location":"#-spyder","text":"\"LANGKAH - LANGKAH CODING\" \u200b - Pertama \u200b Lakukan pengimportan library dari python seperti : \u200b - Numpy -> Untuk operasi vektor dan matriks \u200b - Pandas -> Untuk memuat sebuah file ke dalam tabel virtual seperti spreadsheet. \u200b - Matpolib -> Untuk menyajikan visualisasi data cluster \u200b - Sklearn -> Untuk mengimport library data science import numpy as np import matplotlib.pyplot as plt import pandas as pd from sklearn.cluster import KMeans \u200b - Kedua dataset = pd.read_csv('diabetes.csv') x = dataset.iloc[:, [1, 2, 3, 4]].values wcss = [] Penjelasan : \u200b Coding di atas berfungsing untuk memanggil datasests diabetes. Dan juga untuk memilih baris dan kolom berdasarkan nomer, sesuai urutan bingkai datanya. Dan coding baris terakhir berfungsi untuk memaksimalkan jarak cluster. \u200b - Ketiga for i in range(1, 11): kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0) kmeans.fit(x) wcss.append(kmeans.inertia_) #Plotting the results onto a line graph, allowing us to observe 'The elbow' plt.plot(range(1, 11), wcss) plt.title('The elbow method') plt.xlabel('Number of clusters') plt.ylabel('WCSS') #within cluster sum of squares plt.show() kmeans = KMeans(n_clusters = 3, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0) y_kmeans = kmeans.fit_predict(x) plt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], s = 100, c = 'red', label = 'tested_positive') plt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'tested_negative') #Plotting the centroids of the clusters plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:,1], s = 100, c = 'yellow', label = 'Centroids') plt.legend() Penjelasan : \u200b Coding di atas, berfungsi untuk mengeksekusi dataset yang telah di panggil ke dalam program. Yang nantinya data itu, di kelompokkan masing - masing oleh program sesuai dengan inputan class masing - masing, antara tested positive atau tested negative. Dan untuk membedakan pengelompokkan antara class tested positive dan tested negative, mereka di berikan warna berbeda. Yaitu warna merah untuk tested positive sedangkan warna biru untuk tested negative. Sedangkan warna kuning berfungsi, untuk menampilkan pengelompokkan centroids dari seluruh data. Dan di dalam codingan di atas juga terdapat, coding yang berfungsi menampilkan elbow method. Elbow method berfungsi, membantu menemukan jumlah cluster yang tepat dalam dataset. - Output Program -","title":"- SPYDER"},{"location":"authors-notes/","text":"BIODATA DIRI : \u00b6 Nama : Muhammad Rafi Riva'i Putra N.I.M : 170441100095 Prodi : Sistem Informasi Univ : Universitas Trunojoyo Madura","title":"Biodata"},{"location":"authors-notes/#biodata-diri","text":"Nama : Muhammad Rafi Riva'i Putra N.I.M : 170441100095 Prodi : Sistem Informasi Univ : Universitas Trunojoyo Madura","title":"BIODATA DIRI :"},{"location":"license/","text":"K-Nearest Neighbors (KNN) \u00b6 Pengertian \u00b6 K-Nearest Neighbor (KNN) adalah suatu metode yang menggunakan algoritma supervised. Dimana hasil dari sampel uji yang baru diklasifikasikan berdasarkan mayoritas dari kategori pada KNN. Tujuan dari algoritma ini adalah mengklasifikasi objek baru berdasakan atribut dan sampel latih. pengklasifikasian tidak menggunakan model apapun untuk dicocokkan dan hanya berdasarkan pada memori. Diberikan titik uji, akan ditemukan sejumlah K objek (titik training) yang paling dekat dengan titik uji. Klasifikasi menggunakan voting terbanyak di antara klasifikasi dari K objek. Algoritma KNN menggunakan klasifikasi ketetanggaan sebagai nilai prediksi dari sample uji yang baru. Dekat atau jauhnya tetangga biasanya di hitung berdasarkan jarak Eucledian. \u200b **Gambar K-Nearest Neighbor ** A. Cara Kerja Algoritma K-Nearest Neighbors (KNN) \u00b6 K-nearest neighbors melakukan klasifikasi dengan proyeksi data pembelajaran pada ruang berdimensi banyak. Ruang ini dibagi menjadi bagian-bagian yang merepresentasikan kriteria data pembelajaran. Setiap data pembelajaran direpresentasikan menjadi titik-titik c pada ruang dimensi banyak. B. Algoritma K-Nearest Neighbors \u00b6 Tentukan k bilangan bulat positif berdasarkan ketersediaan data pembelajaran. Pilih tetangga terdekat dari data baru sebanyak k. Tentukan klasifikasi paling umum pada langkah (ii), dengan menggunakan frekuensi terbanyak. Keluaran klasifikasi dari data sampel baru. C. Kelebihan KNN \u00b6 \u200b - KNN memiliki beberapa kelebihan yaitu bahwa dia tangguh terhadap training data yang noisy dan efektif apabila data latih nya besar. D. Kekurangan KNN \u00b6 KNN perlu menentukan nilai dari parameter K (jumlah dari tetangga terdekat). Pembelajaran berdasarkan jarak tidak jelas mengenai jenis jarak apa yang harus digunakan dan atribut mana yang harus digunakan untuk mendapatkan hasil yang terbaik. Biaya komputasi cukup tinggi karena diperlukan perhitungan jarak dari tiap sample uji pada keseluruhan sample latih. IMPLEMENTASI PROGAM K-Nearest Neighbors \u00b6 Di sini, untuk pengimplementasian program saya menggunakan data berupa drugs datasets . Selain data, pengimplementasian membutuhkan software untuk melakukan, pengcodingan program dan di sini saya menggunakan software spyder yang terkoneksi di dalam software anaconda . Alasan saya memilih software spyder, karena pada software spyder yang berada di dalam anaconda, librarynya telah terinstall semua. Tidak seperti pycharm yang harus menginstall librarynya secara manual terlebih dahulu. - ANACONDA \u00b6 - SPYDER \u00b6 \"LANGKAH - LANGKAH CODING\" \u200b - Pertama \u200b Lakukan pengimportan library dari python seperti : \u200b - Numpy -> Untuk operasi vektor dan matriks. \u200b - Pandas -> Untuk memuat sebuah file ke dalam tabel virtual seperti spreadsheet. \u200b - Matpolib -> Untuk menyajikan visualisasi data cluster \u200b - Sklearn -> Untuk mengimport library data science \u200b - Check_Output -> Untuk menyajikan tampilan grafik import numpy as np import pandas as pd from subprocess import check_output from sklearn.preprocessing import LabelEncoder - Kedua \u00b6 df = pd.read_csv('Drugs.csv') y=df.iloc[:,-1] X=df.iloc[:, :-1] X.head() Penjelasan : \u200b Coding di atas berfungsing untuk memanggil datasests drugs. Dan juga untuk memilih baris dan kolom berdasarkan nomer, sesuai urutan bingkai datanya. Baris terakhir digunakan untuk, mengembalikan baris n (5 secara default) teratas dari frame atau seri data. \u200b - Ketiga gender_encoder = LabelEncoder() #Male=1, Female=0 y = gender_encoder.fit_transform(y) y #Standardize features by removing the mean and scaling to unit variance from sklearn.preprocessing import StandardScaler scaler = StandardScaler() scaler.fit(X) X = scaler.transform(X) from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) from sklearn.neighbors import KNeighborsClassifier from sklearn import metrics knn=KNeighborsClassifier() knn.fit(X_train,y_train) y_pred=knn.predict(X_test) print('Accuracy Score:') print(metrics.accuracy_score(y_test,y_pred)) k_range=list(range(1,len(X_train))) acc_score=[] for k in k_range: knn=KNeighborsClassifier(n_neighbors=k) knn.fit(X_train,y_train) y_pred=knn.predict(X_test) acc_score.append(metrics.accuracy_score(y_test,y_pred)) import matplotlib.pyplot as plt k_values=list(range(1,len(X_train))) plt.plot(k_values,acc_score) plt.xlabel('Value of k for knn') plt.ylabel('Accuracy') import operator index, value = max(enumerate(acc_score), key=operator.itemgetter(1)) index value Penjelasan : Coding di atas, berfungsi untuk mengeksekusi dataset yang telah di panggil ke dalam program. Yang nantinya, data itu di proses menjadi accuary score dari drugs datasets. Setelah, di dapatkan accuary score data itu akan di proses kembali agar bisa menyajikan tampilan berupa grafik nilai k untuk knn. - Output Program -","title":"Metode KNN"},{"location":"license/#k-nearest-neighbors-knn","text":"","title":"K-Nearest Neighbors (KNN)"},{"location":"license/#pengertian","text":"K-Nearest Neighbor (KNN) adalah suatu metode yang menggunakan algoritma supervised. Dimana hasil dari sampel uji yang baru diklasifikasikan berdasarkan mayoritas dari kategori pada KNN. Tujuan dari algoritma ini adalah mengklasifikasi objek baru berdasakan atribut dan sampel latih. pengklasifikasian tidak menggunakan model apapun untuk dicocokkan dan hanya berdasarkan pada memori. Diberikan titik uji, akan ditemukan sejumlah K objek (titik training) yang paling dekat dengan titik uji. Klasifikasi menggunakan voting terbanyak di antara klasifikasi dari K objek. Algoritma KNN menggunakan klasifikasi ketetanggaan sebagai nilai prediksi dari sample uji yang baru. Dekat atau jauhnya tetangga biasanya di hitung berdasarkan jarak Eucledian. \u200b **Gambar K-Nearest Neighbor **","title":"Pengertian"},{"location":"license/#a-cara-kerja-algoritma-k-nearest-neighbors-knn","text":"K-nearest neighbors melakukan klasifikasi dengan proyeksi data pembelajaran pada ruang berdimensi banyak. Ruang ini dibagi menjadi bagian-bagian yang merepresentasikan kriteria data pembelajaran. Setiap data pembelajaran direpresentasikan menjadi titik-titik c pada ruang dimensi banyak.","title":"A. Cara Kerja Algoritma K-Nearest Neighbors (KNN)"},{"location":"license/#b-algoritma-k-nearest-neighbors","text":"Tentukan k bilangan bulat positif berdasarkan ketersediaan data pembelajaran. Pilih tetangga terdekat dari data baru sebanyak k. Tentukan klasifikasi paling umum pada langkah (ii), dengan menggunakan frekuensi terbanyak. Keluaran klasifikasi dari data sampel baru.","title":"B. Algoritma K-Nearest Neighbors"},{"location":"license/#c-kelebihan-knn","text":"\u200b - KNN memiliki beberapa kelebihan yaitu bahwa dia tangguh terhadap training data yang noisy dan efektif apabila data latih nya besar.","title":"C. Kelebihan KNN"},{"location":"license/#d-kekurangan-knn","text":"KNN perlu menentukan nilai dari parameter K (jumlah dari tetangga terdekat). Pembelajaran berdasarkan jarak tidak jelas mengenai jenis jarak apa yang harus digunakan dan atribut mana yang harus digunakan untuk mendapatkan hasil yang terbaik. Biaya komputasi cukup tinggi karena diperlukan perhitungan jarak dari tiap sample uji pada keseluruhan sample latih.","title":"D.  Kekurangan KNN"},{"location":"license/#implementasi-progam-k-nearest-neighbors","text":"Di sini, untuk pengimplementasian program saya menggunakan data berupa drugs datasets . Selain data, pengimplementasian membutuhkan software untuk melakukan, pengcodingan program dan di sini saya menggunakan software spyder yang terkoneksi di dalam software anaconda . Alasan saya memilih software spyder, karena pada software spyder yang berada di dalam anaconda, librarynya telah terinstall semua. Tidak seperti pycharm yang harus menginstall librarynya secara manual terlebih dahulu.","title":"IMPLEMENTASI PROGAM K-Nearest Neighbors"},{"location":"license/#-anaconda","text":"","title":"- ANACONDA"},{"location":"license/#-spyder","text":"\"LANGKAH - LANGKAH CODING\" \u200b - Pertama \u200b Lakukan pengimportan library dari python seperti : \u200b - Numpy -> Untuk operasi vektor dan matriks. \u200b - Pandas -> Untuk memuat sebuah file ke dalam tabel virtual seperti spreadsheet. \u200b - Matpolib -> Untuk menyajikan visualisasi data cluster \u200b - Sklearn -> Untuk mengimport library data science \u200b - Check_Output -> Untuk menyajikan tampilan grafik import numpy as np import pandas as pd from subprocess import check_output from sklearn.preprocessing import LabelEncoder","title":"- SPYDER"},{"location":"license/#-kedua","text":"df = pd.read_csv('Drugs.csv') y=df.iloc[:,-1] X=df.iloc[:, :-1] X.head() Penjelasan : \u200b Coding di atas berfungsing untuk memanggil datasests drugs. Dan juga untuk memilih baris dan kolom berdasarkan nomer, sesuai urutan bingkai datanya. Baris terakhir digunakan untuk, mengembalikan baris n (5 secara default) teratas dari frame atau seri data. \u200b - Ketiga gender_encoder = LabelEncoder() #Male=1, Female=0 y = gender_encoder.fit_transform(y) y #Standardize features by removing the mean and scaling to unit variance from sklearn.preprocessing import StandardScaler scaler = StandardScaler() scaler.fit(X) X = scaler.transform(X) from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) from sklearn.neighbors import KNeighborsClassifier from sklearn import metrics knn=KNeighborsClassifier() knn.fit(X_train,y_train) y_pred=knn.predict(X_test) print('Accuracy Score:') print(metrics.accuracy_score(y_test,y_pred)) k_range=list(range(1,len(X_train))) acc_score=[] for k in k_range: knn=KNeighborsClassifier(n_neighbors=k) knn.fit(X_train,y_train) y_pred=knn.predict(X_test) acc_score.append(metrics.accuracy_score(y_test,y_pred)) import matplotlib.pyplot as plt k_values=list(range(1,len(X_train))) plt.plot(k_values,acc_score) plt.xlabel('Value of k for knn') plt.ylabel('Accuracy') import operator index, value = max(enumerate(acc_score), key=operator.itemgetter(1)) index value Penjelasan : Coding di atas, berfungsi untuk mengeksekusi dataset yang telah di panggil ke dalam program. Yang nantinya, data itu di proses menjadi accuary score dari drugs datasets. Setelah, di dapatkan accuary score data itu akan di proses kembali agar bisa menyajikan tampilan berupa grafik nilai k untuk knn. - Output Program -","title":"- Kedua"},{"location":"tambahan/","text":"Decision Tree \u00b6 PENGERTIAN \u00b6 Decision tree adalah salah satu metode klasifikasi yang paling populer, karena mudah untuk diinterpretasi oleh manusia. Decision tree adalah model prediksi menggunakan struktur pohon atau struktur berhirarki. Konsep dari pohon keputusan adalah mengubah data menjadi decision tree dan aturan-aturan keputusan. \"Manfaat utama\" dari penggunaan decision tree adalah kemampuannya untuk mem- break down proses pengambilan keputusan yang kompleks menjadi lebih simple, sehingga pengambil keputusan akan lebih menginterpretasikan solusi dari permasalahan. Nama lain dari decision tree adalah CART ( Classification and Regression Tree ). Dimana metode ini merupakan gabungan dari dua jenis pohon, yaitu classification tree dan juga regression tree . Untuk memudahkan, berikut ilustrasi dari keduanya. \u200b Gambar. Classfication Tree Untuk gambar diatas merupakan contoh dari classification tree, sedangkan gambar dibawah merupakan contoh dari regression tree. \u200b Gambar. Regression Tree Decision tree juga berguna untuk mengeksplorasi data, menemukan hubungan tersembunyi antara sejumlah calon variabel input dengan sebuah variabel target. Decision tree memadukan antara eksplorasi data dan pemodelan, sehingga sangat bagus sebagai langkah awal dalam proses pemodelan bahkan ketika dijadikan sebagai model akhir dari beberapa teknik lain. Dalam beberapa aplikasi, akurasi dari sebuah klasifikasi atau prediksi adalah satu-satunya hal yang ditonjolkan dalam metode ini, misalnya sebuah perusahaan direct mail membuat sebuah model yang akurat untuk memprediksi anggota mana yang berpotensi untuk merespon permintaan, tanpa memperhatikan bagaimana atau mengapa model tersebut bekerja. \u200b Gambar. Decision Tree atau CART Kelebihan lain dari metode ini adalah mampu mengeliminasi perhitungan atau data-data yang kiranya tidak diperlukan. Sebab, sampel yang ada biasanya hanya diuji berdasarkan kriteria atau kelas tertentu saja. Meski memiliki banyak kelebihan, namun bukan berarti metode ini tidak memiliki kekurangan. Decision tree ini bisa terjadi overlap, terutama ketika kelas dan kriteria yang digunakan sangat banyak tentu saja dapat meningkatkan waktu pengambilan keputusan sesuai dengan jumlah memori yang dibutuhkan. Dalam hal akumulasi, decision tree juga seringkali mengalami kendala eror terutama dalam jumlah besar. Selain itu, terdapat pula kesulitan dalam mendesain decision tree yang optimal. Apalagi mengingat kualitas keputusan yang didapatkan dari metode decision tree sangat tergantung pada bagaimana pohon tersebut didesain. Terlepas dari kekurangan dan kelebihan dari decision tree , metode ini banyak digunakan lebih lanjut dalam berbagai pengolahan data. Mulai dari data mining dan juga machine learning . Dalam dunia kerja, decision tree sendiri sangat berguna untuk penilaian credit scoring. Jika anda pernah mengajukan kredit yang diproses secara instan, nah anda sudah mempunyai pengalaman dari decision tree . A. Kelebihan & Kekurangan Pohon Keputusan atau Decision Tree : \u00b6 Kelebihan Metode pohon keputusan mempunyai beberapa kelebihan, diantaranya sebagai berikut : Daerah pengambilan keputusan yang sebelumnya kompleks dan sangat global, dapat diubah menjadi simple dan spesifik. Eliminasi perhitungan-perhitungan yang tidak diperlukan, karena ketika menggunakan metode pohon keputusan maka contoh diuji hanya berdasarkan kriteria atau kelas-kelas tertentu. Fleksibel untuk memilih fitur dari internal node yang berbeda, fitur yang terpilih akan membedakan suatu kriteria dibandingkan kriteria yang lain dalam node yang sama. Metode pohon keputusan dapat menghindari munculnya permasalahan ini dengan menggunakan kriteria yang jumlahnya lebih sedikit pada setiap node internal tanpa banyak mengurangi kualitas keputusan yang dihasilkan. Kekurangan Selain kelebihan dari pohon keputusan, terdapat juga beberapa kekurangan dari pohon keputusan, diantaranya sebagai berikut : Terjadi overlap terutama ketika kelas-kelas dan kriteria yang digunakan jumlahnya sangat banyak. Hal tersebut juga dapat menyebabkan meningkatnya waktu pengambilan keputusan dan jumlah memori yang diperlukan. Pengakumulasian jumlah eror dari setiap tingkat dalam sebuah pohon keputusan yang besar. Kesulitan dalam mendesain pohon keputusan yang optimal Hasil kualitas keputusan yang didapatkan dari metode pohon keputusan sangat tergantung pada bagaimana pohon tersebut didesain. B. Arsitektur Pohon Keputusan \u00b6 Arsitektur pohon keputusan dibuat menyerupai bentuk pohon, dimana pada umumnya sebuah pohon terdapat akar (root), cabang dan daun (leaf). Pada pohon keputusan juga terdiri dari tiga bagian sebagai berikut : a. Root node atau node akar merupakan node yang terletak paling atas dari suatu pohon. b. Internal Node ini merupakan node percabangan, dimana pada node ini hanya terdapat satu input dan mempunyai minimal dua output. c. Leaf Node ini merupakan node akhir, hanya memiliki satu input, dan tidak memiliki output. Pada pohon keputusan setiap leaf node menandai label kelas. Pada pohon keputusan di setiap percabangan menyatakan kondisi yang harus dipenuhi dan tiap ujung pohon menyatakan nilai kelas data. Gambar berikut merupakan bentuk arsitektur pohon keputusan. \u200b Gambar. Arsitektur Pohon Keputusan C. Langkah-Langkah Konstruksi Pohon Keputusan dengan Algoritma \u00b6 Adapun langkah-langkah dalam konstruksi pohon keputusan adalah sebagai berikut : Langkah 1 : Pohon dimulai dengan sebuah simpul yang mereperesentasikan sampel data pelatihan yaitu dengan membuat simpul akar. Langkah 2 : Jika semua sampel berada dalam kelas yang sama, maka simpul ini menjadi daun dan dilabeli menjadi kelas. Jika tidak, information gain akan digunakan untuk memilih atribut terbaik dalam memisahkan data sampel menjadi kelas-kelas individu. Langkah 3 : Cabang akan dibuat untuk setiap nilai pada atribut dan data sampel akan dipartisi lagi. Langkah 4 : Algoritma ini menggunakan proses rekursif untuk membentuk pohon keputusan pada setiap data partisi. Jika sebuah atribut sduah digunakan disebuah simpul, maka atribut ini tidak akan digunakan lagi di simpul anak-anaknya. Langkah 5 : Proses ini berhenti jika dicapai kondisi seperti berikut : \u2013 Semua sampel pada simpul berada di dalam satu kelas \u2013 Tidak ada atribut lainnya yang dapat digunakan untuk mempartisi sampel lebih lanjut. Dalam hal ini akan diterapkan suara terbanyak. Ini berarti mengubah sebuah simpul menjadi daun dan melabelinya dnegan kelas pada suara terbanyak. IMPLEMENTASI PROGAM DECISION TREE \u00b6 Di sini, untuk pengimplementasian program saya menggunakan data berupa bikes datasets . Selain data, pengimplementasian membutuhkan software untuk melakukan, pengcodingan program dan di sini saya menggunakan software spyder yang terkoneksi di dalam software anaconda . Alasan saya memilih software spyder, karena pada software spyder yang berada di dalam anaconda, librarynya telah terinstall semua. Tidak seperti pycharm yang harus menginstall librarynya secara manual terlebih dahulu. - ANACONDA \u00b6 - SPYDER \u00b6 \"LANGKAH - LANGKAH CODING\" \u200b - Pertama \u200b Lakukan pengimportan library dari python seperti : \u200b - Pandas -> Untuk memuat sebuah file ke dalam tabel virtual seperti spreadsheet. import pandas as pd bikes = pd.read_csv('bikes.csv') bikes.head() Penjelasan : \u200b Coding di atas berfungsi untuk memanggil datasests bikes. Dan juga menampilkannya dari perbaris dan kolom. Gambar di bawah adalah hasil output program di atas. \" Output \" \u00b6 \u200b - Kedua \u200b *Lakukan pengimportan pyplot dari library matplotlib from matplotlib import pyplot as plt plt.figure(figsize=(8,6)) plt.plot(bikes['temperature'], bikes['count'], 'o') plt.xlabel('temperature') plt.ylabel('bikes') plt.show() Penjelasan : \u200b Codingan di atas berfungsi untuk, membuat visualisasi berbentuk gambar. Dan bentuk gambar tersaji sesuai, codingan apa yang anda masukkan. Bisa berbentuk grafik maupun yang lain. Dan banyak data, tersaji sesuai dengan plot yang anda masukkan dalam coding anda. Jadi visualisasi data tergantung dari plot yang anda pilih dari range berapa sampai berapanya. Gambar di bawah, merupakan hasil dari visualisasi coding di atas. \" Output \" \u200b - Ketiga \u200b *Lakukan pengimportan DecisionTreeRegressor dari sklearn tree dan juga pengimportan numpy. from sklearn.tree import DecisionTreeRegressor import numpy as np regressor = DecisionTreeRegressor(max_depth=2) regressor.fit(np.array([bikes['temperature']]).T, bikes['count']) Penjelasan : \u200b Codingan di atas berfungsi untuk mengetahui kualitas split data, dari rata - rata kesalahan data yang ada. Dan gambar di bawah merupakan output dari codingan di atas. \u200b \" Output \" \u200b - Keempat xx = np.array([np.linspace(-5, 40, 100)]).T plt.figure(figsize=(8,6)) plt.plot(bikes['temperature'], bikes['count'], 'o', label='observation') plt.plot(xx, regressor.predict(xx), linewidth=4, alpha=.7, label='prediction') plt.xlabel('temperature') plt.ylabel('bikes') plt.legend() plt.show() Penjelasan : Codingan di atas berfungsi untuk, membuat visualisasi berbentuk gambar, yang menjelaskan tentang observasi dari data dan juga prediksi data dari decusion tress. Gambar di bawah ,merupakan ouputan dari coding di atas. \u200b \" Output \" \u200b - Kelima \u200b *Lakukan pengimportan library pydot import pydot !dot -Tpng tree.dot > tree.png from IPython.display import Image Image(filename='tree.png') Penjelasan : Codingan di atas berfungsi untuk megubah file .dot menjadi png . Jadinya dapat memunculkan gambar decission tree, seperti outputan gambar di bawah dari pemrosesan codingan di atas. Sumber Referensi \u00b6 https://medium.com/iykra/mengenal-decision-tree-dan-manfaatnya-b98cf3cf6a8d","title":"Metode Decision-Tree"},{"location":"tambahan/#decision-tree","text":"","title":"Decision Tree"},{"location":"tambahan/#pengertian","text":"Decision tree adalah salah satu metode klasifikasi yang paling populer, karena mudah untuk diinterpretasi oleh manusia. Decision tree adalah model prediksi menggunakan struktur pohon atau struktur berhirarki. Konsep dari pohon keputusan adalah mengubah data menjadi decision tree dan aturan-aturan keputusan. \"Manfaat utama\" dari penggunaan decision tree adalah kemampuannya untuk mem- break down proses pengambilan keputusan yang kompleks menjadi lebih simple, sehingga pengambil keputusan akan lebih menginterpretasikan solusi dari permasalahan. Nama lain dari decision tree adalah CART ( Classification and Regression Tree ). Dimana metode ini merupakan gabungan dari dua jenis pohon, yaitu classification tree dan juga regression tree . Untuk memudahkan, berikut ilustrasi dari keduanya. \u200b Gambar. Classfication Tree Untuk gambar diatas merupakan contoh dari classification tree, sedangkan gambar dibawah merupakan contoh dari regression tree. \u200b Gambar. Regression Tree Decision tree juga berguna untuk mengeksplorasi data, menemukan hubungan tersembunyi antara sejumlah calon variabel input dengan sebuah variabel target. Decision tree memadukan antara eksplorasi data dan pemodelan, sehingga sangat bagus sebagai langkah awal dalam proses pemodelan bahkan ketika dijadikan sebagai model akhir dari beberapa teknik lain. Dalam beberapa aplikasi, akurasi dari sebuah klasifikasi atau prediksi adalah satu-satunya hal yang ditonjolkan dalam metode ini, misalnya sebuah perusahaan direct mail membuat sebuah model yang akurat untuk memprediksi anggota mana yang berpotensi untuk merespon permintaan, tanpa memperhatikan bagaimana atau mengapa model tersebut bekerja. \u200b Gambar. Decision Tree atau CART Kelebihan lain dari metode ini adalah mampu mengeliminasi perhitungan atau data-data yang kiranya tidak diperlukan. Sebab, sampel yang ada biasanya hanya diuji berdasarkan kriteria atau kelas tertentu saja. Meski memiliki banyak kelebihan, namun bukan berarti metode ini tidak memiliki kekurangan. Decision tree ini bisa terjadi overlap, terutama ketika kelas dan kriteria yang digunakan sangat banyak tentu saja dapat meningkatkan waktu pengambilan keputusan sesuai dengan jumlah memori yang dibutuhkan. Dalam hal akumulasi, decision tree juga seringkali mengalami kendala eror terutama dalam jumlah besar. Selain itu, terdapat pula kesulitan dalam mendesain decision tree yang optimal. Apalagi mengingat kualitas keputusan yang didapatkan dari metode decision tree sangat tergantung pada bagaimana pohon tersebut didesain. Terlepas dari kekurangan dan kelebihan dari decision tree , metode ini banyak digunakan lebih lanjut dalam berbagai pengolahan data. Mulai dari data mining dan juga machine learning . Dalam dunia kerja, decision tree sendiri sangat berguna untuk penilaian credit scoring. Jika anda pernah mengajukan kredit yang diproses secara instan, nah anda sudah mempunyai pengalaman dari decision tree .","title":"PENGERTIAN"},{"location":"tambahan/#a-kelebihan-kekurangan-pohon-keputusan-atau-decision-tree","text":"Kelebihan Metode pohon keputusan mempunyai beberapa kelebihan, diantaranya sebagai berikut : Daerah pengambilan keputusan yang sebelumnya kompleks dan sangat global, dapat diubah menjadi simple dan spesifik. Eliminasi perhitungan-perhitungan yang tidak diperlukan, karena ketika menggunakan metode pohon keputusan maka contoh diuji hanya berdasarkan kriteria atau kelas-kelas tertentu. Fleksibel untuk memilih fitur dari internal node yang berbeda, fitur yang terpilih akan membedakan suatu kriteria dibandingkan kriteria yang lain dalam node yang sama. Metode pohon keputusan dapat menghindari munculnya permasalahan ini dengan menggunakan kriteria yang jumlahnya lebih sedikit pada setiap node internal tanpa banyak mengurangi kualitas keputusan yang dihasilkan. Kekurangan Selain kelebihan dari pohon keputusan, terdapat juga beberapa kekurangan dari pohon keputusan, diantaranya sebagai berikut : Terjadi overlap terutama ketika kelas-kelas dan kriteria yang digunakan jumlahnya sangat banyak. Hal tersebut juga dapat menyebabkan meningkatnya waktu pengambilan keputusan dan jumlah memori yang diperlukan. Pengakumulasian jumlah eror dari setiap tingkat dalam sebuah pohon keputusan yang besar. Kesulitan dalam mendesain pohon keputusan yang optimal Hasil kualitas keputusan yang didapatkan dari metode pohon keputusan sangat tergantung pada bagaimana pohon tersebut didesain.","title":"A. Kelebihan &amp; Kekurangan Pohon Keputusan atau Decision Tree :"},{"location":"tambahan/#b-arsitektur-pohon-keputusan","text":"Arsitektur pohon keputusan dibuat menyerupai bentuk pohon, dimana pada umumnya sebuah pohon terdapat akar (root), cabang dan daun (leaf). Pada pohon keputusan juga terdiri dari tiga bagian sebagai berikut : a. Root node atau node akar merupakan node yang terletak paling atas dari suatu pohon. b. Internal Node ini merupakan node percabangan, dimana pada node ini hanya terdapat satu input dan mempunyai minimal dua output. c. Leaf Node ini merupakan node akhir, hanya memiliki satu input, dan tidak memiliki output. Pada pohon keputusan setiap leaf node menandai label kelas. Pada pohon keputusan di setiap percabangan menyatakan kondisi yang harus dipenuhi dan tiap ujung pohon menyatakan nilai kelas data. Gambar berikut merupakan bentuk arsitektur pohon keputusan. \u200b Gambar. Arsitektur Pohon Keputusan","title":"B. Arsitektur Pohon Keputusan"},{"location":"tambahan/#c-langkah-langkah-konstruksi-pohon-keputusan-dengan-algoritma","text":"Adapun langkah-langkah dalam konstruksi pohon keputusan adalah sebagai berikut : Langkah 1 : Pohon dimulai dengan sebuah simpul yang mereperesentasikan sampel data pelatihan yaitu dengan membuat simpul akar. Langkah 2 : Jika semua sampel berada dalam kelas yang sama, maka simpul ini menjadi daun dan dilabeli menjadi kelas. Jika tidak, information gain akan digunakan untuk memilih atribut terbaik dalam memisahkan data sampel menjadi kelas-kelas individu. Langkah 3 : Cabang akan dibuat untuk setiap nilai pada atribut dan data sampel akan dipartisi lagi. Langkah 4 : Algoritma ini menggunakan proses rekursif untuk membentuk pohon keputusan pada setiap data partisi. Jika sebuah atribut sduah digunakan disebuah simpul, maka atribut ini tidak akan digunakan lagi di simpul anak-anaknya. Langkah 5 : Proses ini berhenti jika dicapai kondisi seperti berikut : \u2013 Semua sampel pada simpul berada di dalam satu kelas \u2013 Tidak ada atribut lainnya yang dapat digunakan untuk mempartisi sampel lebih lanjut. Dalam hal ini akan diterapkan suara terbanyak. Ini berarti mengubah sebuah simpul menjadi daun dan melabelinya dnegan kelas pada suara terbanyak.","title":"C. Langkah-Langkah Konstruksi Pohon Keputusan dengan Algoritma"},{"location":"tambahan/#implementasi-progam-decision-tree","text":"Di sini, untuk pengimplementasian program saya menggunakan data berupa bikes datasets . Selain data, pengimplementasian membutuhkan software untuk melakukan, pengcodingan program dan di sini saya menggunakan software spyder yang terkoneksi di dalam software anaconda . Alasan saya memilih software spyder, karena pada software spyder yang berada di dalam anaconda, librarynya telah terinstall semua. Tidak seperti pycharm yang harus menginstall librarynya secara manual terlebih dahulu.","title":"IMPLEMENTASI PROGAM DECISION TREE"},{"location":"tambahan/#-anaconda","text":"","title":"- ANACONDA"},{"location":"tambahan/#-spyder","text":"\"LANGKAH - LANGKAH CODING\" \u200b - Pertama \u200b Lakukan pengimportan library dari python seperti : \u200b - Pandas -> Untuk memuat sebuah file ke dalam tabel virtual seperti spreadsheet. import pandas as pd bikes = pd.read_csv('bikes.csv') bikes.head() Penjelasan : \u200b Coding di atas berfungsi untuk memanggil datasests bikes. Dan juga menampilkannya dari perbaris dan kolom. Gambar di bawah adalah hasil output program di atas.","title":"- SPYDER"},{"location":"tambahan/#output","text":"\u200b - Kedua \u200b *Lakukan pengimportan pyplot dari library matplotlib from matplotlib import pyplot as plt plt.figure(figsize=(8,6)) plt.plot(bikes['temperature'], bikes['count'], 'o') plt.xlabel('temperature') plt.ylabel('bikes') plt.show() Penjelasan : \u200b Codingan di atas berfungsi untuk, membuat visualisasi berbentuk gambar. Dan bentuk gambar tersaji sesuai, codingan apa yang anda masukkan. Bisa berbentuk grafik maupun yang lain. Dan banyak data, tersaji sesuai dengan plot yang anda masukkan dalam coding anda. Jadi visualisasi data tergantung dari plot yang anda pilih dari range berapa sampai berapanya. Gambar di bawah, merupakan hasil dari visualisasi coding di atas. \" Output \" \u200b - Ketiga \u200b *Lakukan pengimportan DecisionTreeRegressor dari sklearn tree dan juga pengimportan numpy. from sklearn.tree import DecisionTreeRegressor import numpy as np regressor = DecisionTreeRegressor(max_depth=2) regressor.fit(np.array([bikes['temperature']]).T, bikes['count']) Penjelasan : \u200b Codingan di atas berfungsi untuk mengetahui kualitas split data, dari rata - rata kesalahan data yang ada. Dan gambar di bawah merupakan output dari codingan di atas. \u200b \" Output \" \u200b - Keempat xx = np.array([np.linspace(-5, 40, 100)]).T plt.figure(figsize=(8,6)) plt.plot(bikes['temperature'], bikes['count'], 'o', label='observation') plt.plot(xx, regressor.predict(xx), linewidth=4, alpha=.7, label='prediction') plt.xlabel('temperature') plt.ylabel('bikes') plt.legend() plt.show() Penjelasan : Codingan di atas berfungsi untuk, membuat visualisasi berbentuk gambar, yang menjelaskan tentang observasi dari data dan juga prediksi data dari decusion tress. Gambar di bawah ,merupakan ouputan dari coding di atas. \u200b \" Output \" \u200b - Kelima \u200b *Lakukan pengimportan library pydot import pydot !dot -Tpng tree.dot > tree.png from IPython.display import Image Image(filename='tree.png') Penjelasan : Codingan di atas berfungsi untuk megubah file .dot menjadi png . Jadinya dapat memunculkan gambar decission tree, seperti outputan gambar di bawah dari pemrosesan codingan di atas.","title":"\" Output \""},{"location":"tambahan/#sumber-referensi","text":"https://medium.com/iykra/mengenal-decision-tree-dan-manfaatnya-b98cf3cf6a8d","title":"Sumber Referensi"}]}